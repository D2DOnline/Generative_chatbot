{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyN1bz7a7ZwA",
        "outputId": "05f3cbc2-c24e-4a4f-835a-8b85f7816c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/D2DOnline/Generative_chatbot.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Generative_chatbot'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)\u001b[K\rremote: Compressing objects:  40% (2/5)\u001b[K\rremote: Compressing objects:  60% (3/5)\u001b[K\rremote: Compressing objects:  80% (4/5)\u001b[K\rremote: Compressing objects: 100% (5/5)\u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OA_w--M7ifD",
        "outputId": "4beed381-fc6a-408c-e9be-9f3175807d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chatboat.ipynb\t  chatgui.py   Generative_chatbot  README.md\t     words.pkl\n",
            "chatbot_model.h5  classes.pkl  intents.json\t   train_chatbot.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PmFVMkv7ooj",
        "outputId": "783f2d83-8ab0-4d2c-8640-5ea1a2863fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Generative_chatbot/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Chatbot/Generative_chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk5xpioW8ThJ",
        "outputId": "8bb90e10-7b25-463f-f462-0a5cf47362cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chatbot.ipynb  human_text.txt  robot_text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsRxEkH7yOU"
      },
      "source": [
        "import re\n",
        "import random\n",
        "data_path = \"human_text.txt\"\n",
        "data_path2 = \"robot_text.txt\"\n",
        "# Defining lines as a list of each line\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "with open(data_path2, 'r', encoding='utf-8') as f:\n",
        "  lines2 = f.read().split('\\n')\n",
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "# Grouping lines by response pair\n",
        "pairs = list(zip(lines,lines2))\n",
        "#random.shuffle(pairs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewnl-wb7721L"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for line in pairs[:400]:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY9VRFH_8gnS"
      },
      "source": [
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhNbq7PT8qfO"
      },
      "source": [
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKRfpQ-i86gw",
        "outputId": "29208e53-99e9-4114-cb8e-a9a78060cbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 50, 1003)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JjqQjndAclM"
      },
      "source": [
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECZ196Z589AK",
        "outputId": "1667a979-b400-46ca-b6bb-c5e9f67828fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 6\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 1.2234 - accuracy: 0.0221 - val_loss: 1.3385 - val_accuracy: 0.0198\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 13s 418ms/step - loss: 1.1355 - accuracy: 0.0241 - val_loss: 1.3784 - val_accuracy: 0.0203\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 13s 417ms/step - loss: 1.1276 - accuracy: 0.0233 - val_loss: 1.4675 - val_accuracy: 0.0190\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 14s 423ms/step - loss: 1.1333 - accuracy: 0.0226 - val_loss: 1.4273 - val_accuracy: 0.0198\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 13s 409ms/step - loss: 1.1004 - accuracy: 0.0244 - val_loss: 1.4661 - val_accuracy: 0.0210\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 13s 418ms/step - loss: 1.0875 - accuracy: 0.0247 - val_loss: 1.4796 - val_accuracy: 0.0203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddKBbJLJB5k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}